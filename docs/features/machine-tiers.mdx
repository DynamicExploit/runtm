---
title: Machine Tiers
description: "Choose the right resources for your workload"
---

Runtm offers three machine tiers. All deployments use **suspended state** by default—machines pause when idle and resume on incoming requests with fast cold starts.

## Choosing a tier

<Tabs>
  <Tab title="starter">
    **256 MB RAM • 1 shared CPU**
    
    The default for most workloads. Good for simple APIs, webhooks, and tools.
    
    ```yaml
    # runtm.yaml
    tier: starter
    ```
  </Tab>
  <Tab title="standard">
    **512 MB RAM • 1 shared CPU**
    
    Required for fullstack apps. Good for web apps with moderate memory usage.
    
    ```yaml
    # runtm.yaml
    tier: standard
    ```
    
    <Note>
    The `web-app` template requires at least `standard` because it runs Node.js and Python simultaneously.
    </Note>
  </Tab>
  <Tab title="performance">
    **1 GB RAM • 2 shared CPUs**
    
    For heavy workloads like AI/ML processing or high-traffic services.
    
    ```yaml
    # runtm.yaml
    tier: performance
    ```
  </Tab>
</Tabs>

## Suspended state

Runtm uses Fly.io's suspended state instead of full machine stops:

- Machines suspend after a period of inactivity
- Resume in ~300-500ms on incoming requests (vs 1-2s for cold start)
- Memory state is preserved during suspension
- You only pay for active compute time

This gives you the cost benefits of serverless with near-instant response times.

## Setting the tier

### In your manifest

```yaml
# runtm.yaml
name: my-service
template: backend-service
runtime: python
tier: standard
```

### At deploy time

Override the manifest tier:

```bash
runtm deploy --tier performance
```

### Change without rebuilding

Use config-only deploys to change tier instantly:

```bash
runtm deploy --tier standard --config-only
```

## Template requirements

| Template | Minimum tier |
|----------|--------------|
| `backend-service` | starter |
| `static-site` | starter |
| `web-app` | standard |

## When to upgrade

- Getting out-of-memory errors → upgrade tier
- Response times degrading under load → upgrade tier
- Running AI models or heavy processing → use performance

Check memory usage in logs:

```bash
runtm logs <deployment_id> --type runtime
```
